{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создать нейронную сеть с нуля, т.е. не используя готовые библиотеки. Пример работы на любом табличном датасете. \n",
    "Сделать класс, в котором реализована возможность задать количество нейронов в скрытом слое и провести обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет с данными о заболеваниях сердца, делим на обучающую и тестовую выборку, в качестве целевой переменной беру Disease (0 - нет патологии, 1 - есть). Так же выполнила one-hot encoding и нормализацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('heart_disease.csv')\n",
    "    df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "    X = df_encoded.drop('Disease', axis=1).values\n",
    "    y = df_encoded['Disease'].values.reshape(-1, 1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"\\nРазмер обучающей выборки: {X_train.shape}\")\n",
    "    print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = X·W + b\n",
    "def linear_regression(X: np.ndarray, weights: np.ndarray, bias: float) -> np.ndarray:\n",
    "    return np.dot(X, weights) + bias\n",
    "\n",
    "# f(x) = 1 / (1 + exp(-x))\n",
    "def activation_function(x: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# производная\n",
    "def activation_derivative(x: np.ndarray) -> np.ndarray:\n",
    "    fx = activation_function(x)\n",
    "    return fx * (1 - fx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=-1):\n",
    "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuron:\n",
    "    def __init__(self, input_size: int, hidden_neurons: int = 0):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        scale = np.sqrt(2.0 / input_size)\n",
    "        \n",
    "        if hidden_neurons > 0:\n",
    "            self.W1 = np.random.randn(input_size, hidden_neurons) * scale\n",
    "            self.b1 = np.zeros((1, hidden_neurons))\n",
    "            self.W2 = np.random.randn(hidden_neurons, 1) * np.sqrt(2.0 / hidden_neurons)\n",
    "            self.b2 = 0.0\n",
    "        else:\n",
    "            self.weights = np.random.randn(input_size) * scale\n",
    "            self.bias = 0.0\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.X = X\n",
    "        \n",
    "        if self.hidden_neurons > 0:\n",
    "            self.z1 = np.dot(X, self.W1) + self.b1\n",
    "            self.a1 = activation_function(self.z1)\n",
    "            \n",
    "            self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "            self.output = activation_function(self.z2)\n",
    "        else:\n",
    "            self.linear_output = np.dot(X, self.weights) + self.bias\n",
    "            self.output = activation_function(self.linear_output)\n",
    "        \n",
    "        if len(self.output.shape) == 1:\n",
    "            self.output = self.output.reshape(-1, 1)\n",
    "            \n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, y_true: np.ndarray, learning_rate: float = 0.01) -> float:\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = y_true.reshape(-1, 1)\n",
    "\n",
    "        m = self.X.shape[0]\n",
    "\n",
    "        error = y_true - self.output\n",
    "        \n",
    "        if self.hidden_neurons > 0:\n",
    "            delta2 = error * activation_derivative(self.z2)\n",
    "            dW2 = np.dot(self.a1.T, delta2) / m\n",
    "            db2 = np.mean(delta2, axis=0)\n",
    "\n",
    "            delta1 = np.dot(delta2, self.W2.T) * activation_derivative(self.z1)\n",
    "            dW1 = np.dot(self.X.T, delta1) / m\n",
    "            db1 = np.mean(delta1, axis=0)\n",
    "\n",
    "            self.W2 += learning_rate * dW2\n",
    "            self.b2 += learning_rate * db2\n",
    "            self.W1 += learning_rate * dW1\n",
    "            self.b1 += learning_rate * db1.reshape(1, -1)\n",
    "        else:\n",
    "\n",
    "            delta = error * activation_derivative(self.linear_output)\n",
    "\n",
    "            dW = np.zeros_like(self.weights)\n",
    "            for i in range(m):\n",
    "                dW += self.X[i] * delta[i, 0]\n",
    "            dW /= m\n",
    "            \n",
    "            db = np.mean(delta)\n",
    "\n",
    "            self.weights += learning_rate * dW\n",
    "            self.bias += learning_rate * db\n",
    "\n",
    "        return np.mean(error ** 2)\n",
    "    \n",
    "    def train(self, X: np.ndarray, y: np.ndarray, epochs: int = 1000, learning_rate: float = 0.01) -> list:\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            loss = self.backward(y, learning_rate)\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, loss: {loss:.6f}\")\n",
    "                \n",
    "        return loss_history\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_neuron(X_train, X_test, y_train, y_test, hidden_neurons=0):\n",
    "\n",
    "    print(f\"{hidden_neurons} нейронов в скрытом слое\\n\")\n",
    "\n",
    "    input_size = X_train.shape[1]\n",
    "    neuron = SimpleNeuron(input_size=input_size, hidden_neurons=hidden_neurons)\n",
    "\n",
    "    loss_history = neuron.train(X_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "    predictions = neuron.predict(X_test)\n",
    "    predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "    accuracy = np.mean(predicted_classes == y_test)\n",
    "\n",
    "    tp = np.sum((predicted_classes == 1) & (y_test == 1))\n",
    "    tn = np.sum((predicted_classes == 0) & (y_test == 0))\n",
    "    fp = np.sum((predicted_classes == 1) & (y_test == 0))\n",
    "    fn = np.sum((predicted_classes == 0) & (y_test == 1))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\\n\")\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(f\"Real {y_test[i][0]}\")\n",
    "        print(f\"Predictions {predictions[i][0]:.4f}\")\n",
    "        print(f\"Predicted {predicted_classes[i][0]}\\n\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Размер обучающей выборки: (216, 13)\n",
      "Размер тестовой выборки: (54, 13)\n",
      "50 нейронов в скрытом слое\n",
      "\n",
      "Epoch 0, loss: 0.346677\n",
      "Epoch 100, loss: 0.280854\n",
      "Epoch 200, loss: 0.247715\n",
      "Epoch 300, loss: 0.232044\n",
      "Epoch 400, loss: 0.221455\n",
      "Epoch 500, loss: 0.212656\n",
      "Epoch 600, loss: 0.204915\n",
      "Epoch 700, loss: 0.198016\n",
      "Epoch 800, loss: 0.191844\n",
      "Epoch 900, loss: 0.186310\n",
      "\n",
      "Accuracy: 0.8519\n",
      "Precision: 0.8824\n",
      "Recall: 0.7143\n",
      "F1-score: 0.7895\n",
      "\n",
      "Real 1\n",
      "Predictions 0.5084\n",
      "Predicted 1\n",
      "\n",
      "Real 1\n",
      "Predictions 0.4971\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.3578\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.2734\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.4322\n",
      "Predicted 0\n",
      "\n",
      "Real 1\n",
      "Predictions 0.5060\n",
      "Predicted 1\n",
      "\n",
      "Real 0\n",
      "Predictions 0.4216\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.3312\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.5260\n",
      "Predicted 1\n",
      "\n",
      "Real 0\n",
      "Predictions 0.3955\n",
      "Predicted 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, column_names = load_dataset()\n",
    "simple_neuron_metrics = test_simple_neuron(X_train, X_test, y_train, y_test, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать GPT как в п.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=-1):\n",
    "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head:\n",
    "    def __init__(self, input_size, head_size=None, dropout=0.0):\n",
    "        self.input_size = input_size\n",
    "        self.head_size = head_size if head_size is not None else input_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        scale = np.sqrt(2.0 / input_size)\n",
    "\n",
    "        self.key_weights = np.random.randn(input_size, self.head_size) * scale\n",
    "        self.query_weights = np.random.randn(input_size, self.head_size) * scale \n",
    "        self.value_weights = np.random.randn(input_size, self.head_size) * scale\n",
    "\n",
    "        self.tril = np.tril(np.ones((input_size, input_size)))\n",
    "\n",
    "        self.output_weights = np.random.randn(self.head_size, 1) * scale\n",
    "        self.output_bias = 0.0\n",
    "    \n",
    "    def apply_dropout(self, x):\n",
    "        if self.dropout > 0:\n",
    "            mask = np.random.rand(*x.shape) > self.dropout\n",
    "            return x * mask / (1 - self.dropout)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.X = x\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        k = np.dot(x, self.key_weights)\n",
    "        q = np.dot(x, self.query_weights)\n",
    "        v = np.dot(x, self.value_weights)\n",
    "\n",
    "        wei = np.matmul(q, k.T) / np.sqrt(k.shape[1])\n",
    "\n",
    "        wei = softmax(wei, axis=-1)\n",
    "\n",
    "        self.attention_weights = self.apply_dropout(wei)\n",
    "\n",
    "        self.attention_output = np.matmul(self.attention_weights, v)\n",
    "\n",
    "        self.linear_output = np.dot(self.attention_output, self.output_weights) + self.output_bias\n",
    "        self.output = activation_function(self.linear_output)\n",
    "\n",
    "        if len(self.output.shape) == 1:\n",
    "            self.output = self.output.reshape(-1, 1)\n",
    "            \n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, y_true, learning_rate=0.01):\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = y_true.reshape(-1, 1)\n",
    "        \n",
    "        batch_size = self.X.shape[0]\n",
    "\n",
    "        error = y_true - self.output\n",
    "        loss = np.mean(error ** 2)\n",
    "\n",
    "        delta_output = error * activation_derivative(self.linear_output)\n",
    "\n",
    "        dW_output = np.dot(self.attention_output.T, delta_output) / batch_size\n",
    "        db_output = np.mean(delta_output)\n",
    "\n",
    "        delta_attention = np.dot(delta_output, self.output_weights.T)\n",
    "\n",
    "        dv = np.dot(self.attention_weights.T, delta_attention)\n",
    "        dW_value = np.dot(self.X.T, dv) / batch_size\n",
    "\n",
    "        dk_dq_factor = delta_attention.sum(axis=1, keepdims=True) / np.sqrt(self.head_size)\n",
    "        dW_key = np.dot(self.X.T, dk_dq_factor) / batch_size\n",
    "        dW_query = np.dot(self.X.T, dk_dq_factor) / batch_size\n",
    "        \n",
    "        self.output_weights += learning_rate * dW_output\n",
    "        self.output_bias += learning_rate * db_output\n",
    "        self.value_weights += learning_rate * dW_value\n",
    "        self.key_weights += learning_rate * dW_key\n",
    "        self.query_weights += learning_rate * dW_query\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.01):\n",
    "        loss_history = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            loss = self.backward(y, learning_rate)\n",
    "            loss_history.append(loss)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, loss: {loss:.6f}\")\n",
    "                \n",
    "        print(f\"Epoch {epochs}, loss: {loss:.6f}\")\n",
    "        \n",
    "        return loss_history\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "        predicted_classes = (predictions > 0.5).astype(int)\n",
    "        \n",
    "        accuracy = np.mean(predicted_classes == y_test)\n",
    "        \n",
    "        tp = np.sum((predicted_classes == 1) & (y_test == 1))\n",
    "        tn = np.sum((predicted_classes == 0) & (y_test == 0))\n",
    "        fp = np.sum((predicted_classes == 1) & (y_test == 0))\n",
    "        fn = np.sum((predicted_classes == 0) & (y_test == 1))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        print(f\"\\nAccuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\\n\")\n",
    "\n",
    "        for i in range(10):\n",
    "            print(f\"Real {y_test[i][0]}\")\n",
    "            print(f\"Predictions {predictions[i][0]:.4f}\")\n",
    "            print(f\"Predicted {predicted_classes[i][0]}\\n\")\n",
    "            \n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simple_head_heart(X_train, X_test, y_train, y_test, head_size=None, dropout=0.0):\n",
    "    input_size = X_train.shape[1]\n",
    "    model = Head(input_size=input_size, head_size=head_size, dropout=dropout)\n",
    "    loss_history = model.train(X_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "    metrics = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.348695\n",
      "Epoch 100, loss: 0.316806\n",
      "Epoch 200, loss: 0.261612\n",
      "Epoch 300, loss: 0.225564\n",
      "Epoch 400, loss: 0.203725\n",
      "Epoch 500, loss: 0.187189\n",
      "Epoch 600, loss: 0.176765\n",
      "Epoch 700, loss: 0.168139\n",
      "Epoch 800, loss: 0.163878\n",
      "Epoch 900, loss: 0.160143\n",
      "Epoch 1000, loss: 0.157642\n",
      "\n",
      "Accuracy: 0.6852, Precision: 0.6667, Recall: 0.3810, F1: 0.4848\n",
      "\n",
      "Real 1\n",
      "Predictions 0.4467\n",
      "Predicted 0\n",
      "\n",
      "Real 1\n",
      "Predictions 0.8549\n",
      "Predicted 1\n",
      "\n",
      "Real 0\n",
      "Predictions 0.1879\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.3854\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.4727\n",
      "Predicted 0\n",
      "\n",
      "Real 1\n",
      "Predictions 0.4989\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.3272\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.2779\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.2113\n",
      "Predicted 0\n",
      "\n",
      "Real 0\n",
      "Predictions 0.2837\n",
      "Predicted 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head_size = X_train.shape[1] // 2\n",
    "simple_head_metrics = test_simple_head_heart(X_train, X_test, y_train, y_test, head_size=head_size, dropout=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
